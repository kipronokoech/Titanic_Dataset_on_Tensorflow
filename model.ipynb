{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division,print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Data Dictionary--------------------\n",
      "\n",
      "Variable|\tDefinition|\tKey|\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "survival| \tSurvival | \t0 = No, 1 = Yes |\n",
      "\n",
      "pclass |\tTicket class |\t1 = 1st, 2 = 2nd, 3 = 3rd|\n",
      "\n",
      "name|  Name of the passenger |-\n",
      "\n",
      "sex |\tSex |\t\n",
      "\n",
      "Age |\tAge in years |\t-\n",
      "\n",
      "sibsp| \t# of siblings / spouses aboard the Titanic |-\n",
      "\n",
      "parch |\t# of parents / children aboard the Titanic \t|-\n",
      "\n",
      "ticket| \tTicket number |\t-\n",
      "\n",
      "fare |\tPassenger fare \t| -\n",
      "\n",
      "cabin |\tCabin number |\t-\n",
      "\n",
      "embarked |\tPort of Embarkation |\tC = Cherbourg, Q = Queenstown, S = Southampton|\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-----------------Variable Notes-----------------------\n",
      "\n",
      "\n",
      "\n",
      "pclass: A proxy for socio-economic status (SES)\n",
      "\n",
      "1st = Upper\n",
      "\n",
      "2nd = Middle\n",
      "\n",
      "3rd = Lower\n",
      "\n",
      "\n",
      "\n",
      "age: Age is fractional if less than 1. If the age is estimated, it is in the form of xx.5\n",
      "\n",
      "\n",
      "\n",
      "sibsp: The dataset defines family relations in this way...\n",
      "\n",
      "Sibling = brother, sister, stepbrother, stepsister\n",
      "\n",
      "Spouse = husband, wife (mistresses and fianc√©s were ignored)\n",
      "\n",
      "\n",
      "\n",
      "parch: The dataset defines family relations in this way...\n",
      "\n",
      "Parent = mother, father\n",
      "\n",
      "Child = daughter, son, stepdaughter, stepson\n",
      "\n",
      "Some children travelled only with a nanny, therefore parch=0 for them.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"data_description.txt\",\"r\") as fp:\n",
    "    for line in fp:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the training data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 10)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/titanic.csv\")\n",
    "print(data.shape) #891 data points for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.iloc[:700,:].reset_index()\n",
    "val = data.iloc[701:,:].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'survived', 'sex', 'age', 'n_siblings_spouses', 'parch',\n",
       "       'fare', 'class', 'deck', 'embark_town', 'alone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engeenering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are interested in predicting whether a passanger survived or not\n",
    "#so Survived column becomes our labels\n",
    "#pop the labels into ytrain\n",
    "ytrain = train.pop(\"survived\")\n",
    "yval = val.pop(\"survived\")\n",
    "#after popping the labels train datafram contains the feature columns only and not\n",
    "#Survived columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n",
    "#                        'embark_town', 'alone']\n",
    "CATEGORICAL_COLUMNS = ['sex', 'class', 'deck','n_siblings_spouses','parch', 'alone']\n",
    "NUMERIC_COLUMNS = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "    vocabulary = train[feature_name].unique()  # gets a list of all unique values from given feature column\n",
    "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
    "\n",
    "#print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one case of the above loop\n",
    "vocabulary = train[\"sex\"].unique()\n",
    "tf.feature_column.categorical_column_with_vocabulary_list(\"sex\", vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(data_df, label_df, epochs=500, shuffle=True, batch_size=16):\n",
    "    def input_function():  # inner function, this will be returned\n",
    "        #creating tensorflow object for which we will train the model on\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "        if shuffle:\n",
    "            # randomize order of data\n",
    "            ds = ds.shuffle(1000)  \n",
    "        # split dataset into batches of 32 and repeat process for number of epochs\n",
    "        ds = ds.batch(batch_size).repeat(epochs)  \n",
    "        return ds  # return a batch of the dataset\n",
    "    return input_function  # return a function object for use\n",
    "\n",
    "train_input_fn = make_input_fn(train, ytrain)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n",
    "eval_input_fn = make_input_fn(val, yval, epochs=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a linear estimtor by passing the feature columns we created earlier\n",
    "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    " # train the model\n",
    "linear_est.train(train_input_fn) \n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.81857145, 'accuracy_baseline': 0.61142856, 'auc': 0.8767481, 'auc_precision_recall': 0.8507003, 'average_loss': 0.4122788, 'label/mean': 0.38857144, 'loss': 6.558981, 'precision': 0.78431374, 'prediction/mean': 0.39817023, 'recall': 0.7352941, 'global_step': 22000}\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model on the train data\n",
    "result_train = linear_est.evaluate(train_input_fn) \n",
    "clear_output() #Clear the console\n",
    "print(result_train) #model perfomance on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.77894735, 'accuracy_baseline': 0.63684213, 'auc': 0.83369267, 'auc_precision_recall': 0.74817693, 'average_loss': 0.4813557, 'label/mean': 0.3631579, 'loss': 7.621465, 'precision': 0.68, 'prediction/mean': 0.4087389, 'recall': 0.73913044, 'global_step': 22000}\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model on the train data\n",
    "result_val = linear_est.evaluate(eval_input_fn) \n",
    "clear_output() #Clear the console\n",
    "print(result_val) #model perfomance on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': array([-2.4195952], dtype=float32),\n",
       " 'logistic': array([0.08169058], dtype=float32),\n",
       " 'probabilities': array([0.91830933, 0.08169061], dtype=float32),\n",
       " 'class_ids': array([0]),\n",
       " 'classes': array([b'0'], dtype=object),\n",
       " 'all_class_ids': array([0, 1], dtype=int32),\n",
       " 'all_classes': array([b'0', b'1'], dtype=object)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#this is how one predictions will look like\n",
    "pred_dicts = list(linear_est.predict(eval_input_fn))\n",
    "clear_output()\n",
    "pred_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prob of surviving</th>\n",
       "      <th>prediction</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.081691</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.091583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.120701</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.105153</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.740305</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.978332</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.726106</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.347600</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.114053</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.992481</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.069428</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.868939</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.708616</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.068282</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.796979</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.908186</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.974049</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.233884</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.104228</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.978951</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Prob of surviving  prediction  actual\n",
       "0            0.081691           0       0\n",
       "1            0.091583           0       1\n",
       "2            0.120701           0       0\n",
       "3            0.105153           0       1\n",
       "4            0.740305           1       1\n",
       "5            0.978332           1       1\n",
       "6            0.726106           1       0\n",
       "7            0.347600           0       0\n",
       "8            0.114053           0       0\n",
       "9            0.992481           1       0\n",
       "10           0.069428           0       1\n",
       "11           0.868939           1       1\n",
       "12           0.708616           1       1\n",
       "13           0.068282           0       0\n",
       "14           0.796979           1       1\n",
       "15           0.908186           1       1\n",
       "16           0.974049           1       1\n",
       "17           0.233884           0       0\n",
       "18           0.104228           0       0\n",
       "19           0.978951           1       1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predictions on the validation data\n",
    "pred_dicts = list(linear_est.predict(eval_input_fn))\n",
    "clear_output()\n",
    "probs = pd.DataFrame(pd.Series([pred['probabilities'][1] for pred in pred_dicts]),columns=[\"Prob of surviving\"])\n",
    "probs[\"prediction\"] = pd.Series([int(pred[\"class_ids\"]) for pred in pred_dicts])\n",
    "probs[\"actual\"] = pd.Series(yval)\n",
    "probs.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanicvenv",
   "language": "python",
   "name": "titanicvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
