{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division,print_function\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import seaborn\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------Data Dictionary--------------------\n",
      "\n",
      "Variable|\tDefinition|\tKey|\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "survival| \tSurvival | \t0 = No, 1 = Yes |\n",
      "\n",
      "pclass |\tTicket class |\t1 = 1st, 2 = 2nd, 3 = 3rd|\n",
      "\n",
      "name|  Name of the passenger |-\n",
      "\n",
      "sex |\tSex |\t\n",
      "\n",
      "Age |\tAge in years |\t-\n",
      "\n",
      "sibsp| \t# of siblings / spouses aboard the Titanic |-\n",
      "\n",
      "parch |\t# of parents / children aboard the Titanic \t|-\n",
      "\n",
      "ticket| \tTicket number |\t-\n",
      "\n",
      "fare |\tPassenger fare \t| -\n",
      "\n",
      "cabin |\tCabin number |\t-\n",
      "\n",
      "embarked |\tPort of Embarkation |\tC = Cherbourg, Q = Queenstown, S = Southampton|\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-----------------Variable Notes-----------------------\n",
      "\n",
      "\n",
      "\n",
      "pclass: A proxy for socio-economic status (SES)\n",
      "\n",
      "1st = Upper\n",
      "\n",
      "2nd = Middle\n",
      "\n",
      "3rd = Lower\n",
      "\n",
      "\n",
      "\n",
      "age: Age is fractional if less than 1. If the age is estimated, it is in the form of xx.5\n",
      "\n",
      "\n",
      "\n",
      "sibsp: The dataset defines family relations in this way...\n",
      "\n",
      "Sibling = brother, sister, stepbrother, stepsister\n",
      "\n",
      "Spouse = husband, wife (mistresses and fianc√©s were ignored)\n",
      "\n",
      "\n",
      "\n",
      "parch: The dataset defines family relations in this way...\n",
      "\n",
      "Parent = mother, father\n",
      "\n",
      "Child = daughter, son, stepdaughter, stepson\n",
      "\n",
      "Some children travelled only with a nanny, therefore parch=0 for them.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"data_description.txt\",\"r\") as fp:\n",
    "    for line in fp:\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the training data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 10)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"./data/titanic.csv\")\n",
    "print(train.shape) #891 data points for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['survived', 'sex', 'age', 'n_siblings_spouses', 'parch', 'fare',\n",
       "       'class', 'deck', 'embark_town', 'alone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engeenering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are interested in predicting whether a passanger survived or not\n",
    "#so Survived column becomes our labels\n",
    "#pop the labels into ytrain\n",
    "ytrain = train.pop(\"survived\")\n",
    "#after popping the labels train datafram contains the feature columns only and not\n",
    "#Survived columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck',\n",
    "                       'embark_town', 'alone']\n",
    "NUMERIC_COLUMNS = ['age', 'fare']\n",
    "\n",
    "feature_columns = []\n",
    "for feature_name in CATEGORICAL_COLUMNS:\n",
    "    vocabulary = train[feature_name].unique()  # gets a list of all unique values from given feature column\n",
    "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary))\n",
    "\n",
    "for feature_name in NUMERIC_COLUMNS:\n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32))\n",
    "\n",
    "#print(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VocabularyListCategoricalColumn(key='sex', vocabulary_list=('male', 'female'), dtype=tf.string, default_value=-1, num_oov_buckets=0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one case of the above loop\n",
    "vocabulary = train[\"sex\"].unique()\n",
    "tf.feature_column.categorical_column_with_vocabulary_list(\"sex\", vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(data_df, label_df, num_epochs=50, shuffle=True, batch_size=32):\n",
    "    def input_function():  # inner function, this will be returned\n",
    "        #creating tensorflow object for which we will train the model on\n",
    "        ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))\n",
    "        if shuffle:\n",
    "            # randomize order of data\n",
    "            ds = ds.shuffle(1000)  \n",
    "        # split dataset into batches of 32 and repeat process for number of epochs\n",
    "        ds = ds.batch(batch_size).repeat(num_epochs)  \n",
    "        return ds  # return a batch of the dataset\n",
    "    return input_function  # return a function object for use\n",
    "\n",
    "train_input_fn = make_input_fn(train, ytrain)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n",
    "#eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp4y5h696i\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp4y5h696i', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe46b235748>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# We create a linear estimtor by passing the feature columns we created earlier\n",
    "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.81705946, 'accuracy_baseline': 0.6161616, 'auc': 0.86898565, 'auc_precision_recall': 0.84195495, 'average_loss': 0.42431173, 'label/mean': 0.3838384, 'loss': 13.502206, 'precision': 0.7609329, 'prediction/mean': 0.40397578, 'recall': 0.7631579, 'global_step': 1400}\n"
     ]
    }
   ],
   "source": [
    " # train the model\n",
    "linear_est.train(train_input_fn) \n",
    "#evaluate the model on the train data\n",
    "result_train = linear_est.evaluate(train_input_fn) \n",
    "clear_output() #Clear the console\n",
    "print(result_train) #model perfomance on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_input_fn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-95-50fc82edd23f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_dicts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear_est\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpred_dicts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_input_fn' is not defined"
     ]
    }
   ],
   "source": [
    "pred_dicts = list(linear_est.predict(eval_input_fn))\n",
    "clear_output()\n",
    "pred_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanicvenv",
   "language": "python",
   "name": "titanicvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
